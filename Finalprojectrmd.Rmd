---
title: "Final Project"
author: "David Counter"
date: "December 17, 2019"
output: html_document
---

#Introduction

	The Stat 425 final project is about working with big data and creating the best model to use for the predication of sales of products as it relates to weather events. This data was aggregated by Walmart back in 2014, taken from 45 different stores with 20 different weather reporting stations across these areas. The train data provided by Walmart gives us the data across these stores for the amount of a particular item sold, its item id and is organized by date. The test csv is what Kaggle tests our model against; the data for these dates and stores is known, and we will be given a score based upon how accurate our model is in comparison to its actual values.

	Walmart also of course provides weather data across 20 stations per day. There’s extensive data on rainfall, wind speed, temperature, significant weather events and so on. Predictors like pressure, monthly rainfall, average sea level pressure and so on might not be that influential in terms of the final model, however we will see should our prediction on these variables might change. We will have to use these potential 74 variables to create a model which predicts the sales of each product in the test data. First initially starting with a “full” Ordinary least squares model, we will do some model selection, possible ridge or lasso scaling, and take into account collinearity, covariance and so on.  After this model selection, we will use it to predict the data with the test.csv data. Kaggle will return a score, the lower of which will be better. Our lowest Kaggle score will be our “best model” and this is what will be scored in the final grade. Finally, at the end we’ll include all relevant graphs and tables, as well as all code that is used in the report.
	
	
#Linear Regression Model / Diagnostics 
```{r data load}
####RUN AT STARTUP


#loaded Packages
library(foreach)
library(parallel)
library(doParallel)
library(dplyr)
library(lubridate)
library(glmnet)

#initialized data
train <- read.csv("train.csv")
weather <- read.csv("weather.csv", stringsAsFactors = FALSE)
test<- read.csv("test.csv")
#key <- read.csv("key.csv")
mergedata <- read.csv("mergedata.csv")
sample <- read.csv("sampleSubmission.csv")
mergedtestdata = read.csv("mergedtestdata.csv")
#drops <- c("X", "key", "codesum", "station_nbr")
#mergedata <- mergedata[ , !names(mergedata) %in% drops]
#testy <- testy[ , !names(testy) %in% drops]


#set backup
#trainbackup <- train
#weatherbackup <- weather
#testbackup <- test

#set dates to date format
train$date <- as.Date(train$date, "%Y-%m-%d")
#weather$date <- as.Date(weather$date, "%Y-%m-%d")
test$date <- as.Date(test$date, "%Y-%m-%d")



```

```{r weather clean}
weatherclean = weather
weatherclean[weatherclean == "M"] = NA
weatherclean[weatherclean == weatherclean$snowfall[37]] = 0
weatherclean[weatherclean == "-'"] = NA
weatherclean$date = as.Date(weatherclean$date, "%Y-%m-%d")

weatherdrops = c("depart", "sunrise", "sunset", "codesum")
weatherclean <- weatherclean[ , !names(weatherclean) %in% weatherdrops]

for(i in colnames(weatherclean)[colnames(weatherclean) != "date" & colnames(weatherclean) != "station_nbr"]){
  weatherclean[[i]] = as.integer(weatherclean[[i]])
}
weatherclean = weatherclean[with(weatherclean, order(weatherclean$station_nbr, weatherclean$date)),]
weatherclean$event = 0


for(i in 1:nrow(weatherclean)){
  weatherclean$event[i] = 4 * (weatherclean$snowfall[i] >= 2 | weatherclean$preciptotal[i] >= 1)
}
weatherclean$event[is.na(weatherclean$event)] = FALSE

weatherclean$eventdist = weatherclean$event

for(i in 2:20516){
    if(weatherclean$event[i+1] >= 4 | weatherclean$event[i-1] >= 4 & weatherclean$eventdist[i] != 4){
        weatherclean$eventdist[i] = 3}}
for(i in 3:20515){
    if(weatherclean$event[i+2] >= 4 | weatherclean$event[i-2] >= 4 & weatherclean$eventdist[i] < 3){
        weatherclean$eventdist[i] = 2}}
for(i in 4:20514){
    if(weatherclean$event[i+3] >= 4 | weatherclean$event[i-3] >= 4 & weatherclean$eventdist[i] == 0){
        weatherclean$eventdist[i] = 1}}

weatherclean <- weatherclean[ , !names(weatherclean) %in% c("event")]

weatherclean$day_of_week = wday(weatherclean$date, label = TRUE)
weatherclean$weekend[weatherclean$day_of_week == "Sun" | weatherclean$day_of_week == "Sat"] = TRUE
weatherclean$weekend[weatherclean$day_of_week != "Sun" & weatherclean$day_of_week != "Sat"] = FALSE
weatherclean$month = month(weatherclean$date)

write.csv(weatherclean, "weatherclean.csv")
```

```{r data merge}
keymerge <- rep(1,4617600)

key<- read.csv("key.csv")

#Don't run it this way unless you have 24 hours to let your computer run
#converts all store numbers based on key to merge with weather
for(i in 1:4617600){
    keymerge[i] = key$station_nbr[train$store_nbr[i]]
  }

train<-cbind("station_nbr" = keymerge, train)
  
mergedata <- merge(train, weatherclean, by = c("date", "station_nbr"))
mergedata <- mergedata[with(mergedata, order(mergedata$date, mergedata$store_nbr, mergedata$item_nbr)),]
write.csv(mergedata, "mergedata.csv")

keytest <- rep(0, nrow(test))
#create key
for(i in 1:nrow(test)){
    keytest[i] = key$station_nbr[test$store_nbr[i]]
  }
test <- cbind("station_nbr" = keytest, test)


#merges test data with merge data to create a from for prediction
mergedtestdata <- merge(test, weatherclean,  by = c("date", "station_nbr"))
drops <- c("X.1", "X")
mergedtestdata <- mergedtestdata[ , !names(mergedtestdata) %in% drops]
mergedtestdata <- mergedtestdata[with(mergedtestdata, order(mergedtestdata$date, mergedtestdata$store_nbr, mergedtestdata$item_nbr)),]

write.csv(mergedtestdata, "mergedtestdata.csv")

```

```{r dataclean}
#applies data converting to remove as factor variables
mergedata <- read.csv("mergedata.csv")
mergedata <- mergedata[ , !names(mergedata) %in% c("X")]

mergedata$date <- as.Date(mergedata$date, "%Y-%m-%d")
mergedata$store_nbr <- as.factor(mergedata$store_nbr)
mergedata$item_nbr <- as.factor(mergedata$item_nbr)

mergedtestdata <- read.csv("mergedtestdata.csv")

mergedtestdata$date <- as.Date(mergedtestdata$date, "%Y-%m-%d")
mergedtestdata$store_nbr <- as.factor(mergedtestdata$store_nbr)
mergedtestdata$item_nbr <- as.factor(mergedtestdata$item_nbr)
```

```{r OLS}

SampleOLS <- sample
mergedata <- read.csv("mergedata.csv")
mergedata <- mergedata[ , !names(mergedata) %in% c("X")]
mergedata$date <- as.Date(mergedata$date, "%Y-%m-%d")
mergedtestdata <- read.csv("mergedtestdata.csv")
mergedtestdata$date <- as.Date(mergedtestdata$date, "%Y-%m-%d")

#OLS model
OLSModel <- lm(units ~ . , data = mergedata)

summary(OLSModel)


predictionOLS <- predict(OLSModel, newdata = mergedtestdata)
predictionOLS[is.na(predictionOLS)] <- 0

SampleOLS$units <- predictionOLS

write.csv(x = SampleOLS, file =  "SampleOLS.csv", row.names = FALSE)


```

```{r AIC}
SampleAIC <- sample
mergedata <- read.csv("mergedata.csv")
mergedata <- mergedata[ , !names(mergedata) %in% c("X")]
mergedata$date <- as.Date(mergedata$date, "%Y-%m-%d")
mergedtestdata <- read.csv("mergedtestdata.csv")
mergedtestdata$date <- as.Date(mergedtestdata$date, "%Y-%m-%d")





AICModel <- step(OLSModel)

predictionAIC <- predict(OLSModel, newdata = mergedtestdata)
predictionAIC[is.na(predictionAIC)] <- 0

SampleAIC$units <- predictionAIC

write.csv(x = SampleOLS, file =  "SampleAIC.csv", row.names = FALSE)

```

After running our linear model, we tried to run Ridge/Lasso to eliminate overfitting on our predictors. The predictor we chose were based upon our data analysis of the weather data, leading us to largely ignore these predictors altogether. As with our other models, we had store number and item number as factors in addiion to day of the week and our "id" factor which gives us a combined reference code for each combination of the two. Black Friday was created as a binary variable to attempt to catch any significant deviations from the norm on America's greatest capitalist holiday. Date was also removed as it seemed to be redundant and we had created additional predictors to account for date anyway however was added back in as our kaggle score decreased with date as a predictor. We used our created variables in addition to the ones present in the train dataset. Using cross validation to find our optimal lamdas, we ran Ridge and Lasso models, creating a model matrix for our test data and used y as a dummy variable in our test Matrix to extract the prediction values. 

These models returned a moderate kaggle score, which improved upon the OLS model significantly. Both Ridge and Lasso came back with scores roughly around ~ 0.24 - 0.25. 




```{r Lasso}
refineddata <- read.csv("refined_data.csv")
refineddata$store_nbr <- as.factor(refineddata$store_nbr)
refineddata$item_nbr <- as.factor(refineddata$item_nbr)
refineddata$date <- as.Date(refineddata$date, "%Y-%m-%d")


SampleLASSO <- sample
mergedtestdata <- read.csv("mergedtestdata.csv")
mergedtestdata$store_nbr <- as.factor(mergedtestdata$store_nbr)
mergedtestdata$item_nbr <- as.factor(mergedtestdata$item_nbr)
mergedtestdata$date <- as.Date(mergedtestdata$date, "%Y-%m-%d")

units <- refineddata$units

modelmatrix <- model.matrix(lm(units~date +store_nbr+item_nbr+eventdist+day_of_week+weekend+month+blackFriday, family = gaussian, data = refineddata))[, -36]
y=seq(1, nrow(mergedtestdata), by = 1)
mergedtestdata$y = y
modelmatrixtest <- model.matrix(lm(y ~ date+store_nbr+item_nbr+eventdist+day_of_week+weekend+month+blackFriday, family = gaussian, data = mergedtestdata))

lambdas = 10^seq(3, -2, by = -.1)
CVglm = cv.glmnet(x = modelmatrix, y = units, family = "gaussian", alpha = 1)
GLMModel <- glmnet(x = modelmatrix, y=units,  family="gaussian", alpha = 1, lambda = CVglm$lambda.min)

predictionLASSO <- predict(GLMModel, newx = modelmatrixtest, type ="response")

predictions <- predictionLASSO
predictions[!mergedtestdata$id %in% refineddata$id] = 0
predictions[is.na(predictions)] <- 0

SampleLASSO$units <- predictions

write.csv(x = SampleLASSO, file =  "SampleLASSO.csv", row.names = FALSE)
```


```{r Ridge}
refineddata <- read.csv("refined_data.csv")
refineddata$store_nbr <- as.factor(refineddata$store_nbr)
refineddata$item_nbr <- as.factor(refineddata$item_nbr)
refineddata$date <- as.Date(refineddata$date, "%Y-%m-%d")


SampleRIDGE <- sample
mergedtestdata <- read.csv("mergedtestdata.csv")
mergedtestdata$store_nbr <- as.factor(mergedtestdata$store_nbr)
mergedtestdata$item_nbr <- as.factor(mergedtestdata$item_nbr)
mergedtestdata$date <- as.Date(mergedtestdata$date, "%Y-%m-%d")

units <- refineddata$units

modelmatrix <- model.matrix(lm(units~date+store_nbr+item_nbr+eventdist+day_of_week+weekend+month+blackFriday, family = gaussian, data = refineddata))[, -36]
y=seq(1, nrow(mergedtestdata), by = 1)
mergedtestdata$y = y
modelmatrixtest <- model.matrix(lm(y ~ date+store_nbr+item_nbr+eventdist+day_of_week+weekend+month+blackFriday, family = gaussian, data = mergedtestdata))

lambdas = 10^seq(3, -2, by = -.1)
CVglm = cv.glmnet(x = modelmatrix, y = units, family = "gaussian", alpha = 0)
GLMModel <- glmnet(x = modelmatrix, y=units,  family="gaussian", alpha = 0, lambda = CVglm$lambda.min)

predictionRIDGE <- predict(GLMModel, newx = modelmatrixtest, type ="response")

predictions <- predictionRIDGE
predictions[!mergedtestdata$id %in% refineddata$id] = 0
predictions[is.na(predictions)] <- 0

SampleRIDGE$units <- predictions

write.csv(x = SampleRIDGE, file =  "SampleRIDGE.csv", row.names = FALSE)
```
Even though our linear model had errors that were close to normal, we thought that exploring different models might be a good idea in fiting our model. Generalized linear modeling allows non-normal variables to be mapped linearly to the response variable. This comes in the form of a "link" function, which forms the response variables based on certain families of distributions. The Gaussian distribution is in the normal family of distributions. We used Gaussian fitting to try and normalize our results in case we missed any non normal variables within our model. 

We chose the same predictors as before, as with our fitting we found that these predictors worked best on our models response variable as it related to our kaggle score. We wanted to use the created variables witin this data, as dropping any of them actually made our kaggle score worse, especially date, weekday, and month. This score however didn't improve greatly on our kaggle score and was more in line with our Lasso and Ridge scores rather than our

```{r glm}
refineddata <- read.csv("refined_data.csv")
refineddata$store_nbr <- as.factor(refineddata$store_nbr)
refineddata$item_nbr <- as.factor(refineddata$item_nbr)
refineddata$date <- as.Date(refineddata$date, "%Y-%m-%d")


SampleGLM <- sample
mergedtestdata <- read.csv("mergedtestdata.csv")
mergedtestdata$store_nbr <- as.factor(mergedtestdata$store_nbr)
mergedtestdata$item_nbr <- as.factor(mergedtestdata$item_nbr)
mergedtestdata$date <- as.Date(mergedtestdata$date, "%Y-%m-%d")

units <- refineddata$units

GLMModel<-glm(units~date+store_nbr+item_nbr+eventdist+day_of_week+weekend+month+blackFriday, family = gaussian, data = refineddata)

predictionGLM <- predict(GLMModel, mergedtestdata)
predictions <- predictionGLM
predictions[!mergedtestdata$id %in% refineddata$id] = 0

SampleGLM$units <- predictions

write.csv(x = SampleGLM, file =  "SampleGLM.csv", row.names = FALSE)
```
























